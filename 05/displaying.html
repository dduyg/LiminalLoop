<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Liminal Loop</title>
    <link href="https://fonts.googleapis.com/css2?family=Funnel+Display:wght@300..800&display=swap" rel="stylesheet">
    <style>
        body {
            margin: 0;
            font-family: "Funnel Display", sans-serif;
            color: black;
            background-color: #EAE0D5;
            line-height: 1.6;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header p {
            font-size: 1.2rem;
            margin-bottom: 20px;
        }
        section {
            display: flex;
            flex-direction: column;
            gap: 50px;
        }
        .lead {
            display: flex;
            align-items: center;
            gap: 20px;
        }
        .profile img {
            border-radius: 50%;
            width: 150px;
            height: 150px;
            object-fit: cover;
        }
        .description h2 {
            font-size: 1.5rem;
            margin-bottom: 10px;
        }
        .pointer {
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <p>Diffusion models are advanced generative frameworks that learn data distributions by reversing a noise process.</p>
            <p>By incrementally denoising data, these models excel in creating high-quality samples for diverse fields like images, audio, and 3D modeling.</p>
            <p>Using noise scheduling and precise training, diffusion models reconstruct data while capturing rich representations for diverse applications in modern artificial intelligence.</p>
        </header>

        <section>
            <div class="lead">
                <div class="profile">
                    <img src="https://media3.giphy.com/media/LetlUx0AvLDK0cXAg1/giphy.gif">
                </div>
                <div class="description">
                    <h2>Diffusion Models in AI</h2>
                    <p>Diffusion models introduce noise to data and then learn how to reverse this process step-by-step. This ability is leveraged for generative tasks, where output quality improves with every denoising iteration. These models rely on careful scheduling of noise addition during training, ensuring smooth sample generation. The process is computationally intensive but produces sharp, detailed, and realistic outcomes.</p>
                    <p>Applications range from generating photorealistic images to synthesizing diverse types of content, like speech and molecular data. Notable advancements include their integration into AI tools like Stable Diffusion and DALLÂ·E. Researchers continue to refine these methods, aiming to improve efficiency and adaptability. Diffusion models are poised to redefine creativity in AI-driven innovations, enabling richer generative experiences.</p>
                </div>
            </div>

            <div class="pointer">
                <h3>Applications</h3>
                <p>Diffusion models are now used for text-to-image generation, protein folding analysis, video synthesis, and even in AI-powered art. By combining mathematical rigor with modern computational power, they have become a foundation for generative modeling. Their versatility and performance continue to fuel innovation in the AI landscape.</p>
            </div>
        </section>
    </div>
</body>
</html>
